{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUDCell(nn.Module):\n",
    "    def __init__(self, input_size_cnn, input_size, hidden_size, bias=True):\n",
    "        super(GRUDCell, self).__init__()\n",
    "\n",
    "        self.convfc_size = 4\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=4)\n",
    "        self.convfc = nn.Linear(32 * 16, self.convfc_size)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "\n",
    "        self.input_size_cnn = input_size_cnn\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.delta_size = input_size\n",
    "        self.mask_size = input_size\n",
    "        self.bias = bias\n",
    "        self.x2h = nn.Linear(input_size + self.convfc_size, 3 * hidden_size, bias=bias)\n",
    "        self.h2h = nn.Linear(hidden_size, 3 * hidden_size, bias=bias)\n",
    "        self.m2h = nn.Linear(input_size + self.convfc_size, 3 * hidden_size, bias=bias)\n",
    "        self.d2r = nn.Linear(input_size + self.convfc_size, hidden_size, bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x_cnn, x, mask, delta, hidden):\n",
    "        \n",
    "        # cnn in historical price data, to get the trend of the stock\n",
    "        print(x_cnn.shape,x.shape)\n",
    "        x_cnn = x_cnn.view(-1, 1, self.input_size_cnn)\n",
    "        x_conv1 = F.relu(self.conv1(x_cnn))\n",
    "        x_conv2 = F.relu(self.conv2(x_conv1))\n",
    "        x_conv2 = x_conv2.view(x_conv2.size(0), -1)\n",
    "        x_fc = self.convfc(x_conv2)\n",
    "        x_fc = self.drop(x_fc)\n",
    "\n",
    "        # GRUD\n",
    "        x = x.view(-1, x.size(1))\n",
    "        x = torch.cat((x,x_fc), 1)\n",
    "        delta = torch.cat((delta, torch.ones((x.size(0),self.convfc_size)).cuda()), 1)\n",
    "        mask = torch.cat((mask, torch.ones((x.size(0), self.convfc_size)).cuda()), 1)\n",
    "\n",
    "        rt = torch.exp(-torch.max(torch.zeros(self.hidden_size).cuda(), self.d2r(delta)))\n",
    "\n",
    "        gate_x = self.x2h(x)\n",
    "        gate_h = self.h2h(rt * hidden)\n",
    "        gate_m = self.m2h(mask)\n",
    "\n",
    "        gate_x = gate_x.squeeze()\n",
    "        gate_h = gate_h.squeeze()\n",
    "        gate_m = gate_m.squeeze()\n",
    "\n",
    "        i_r, i_i, i_n = gate_x.chunk(3, 1)\n",
    "        h_r, h_i, h_n = gate_h.chunk(3, 1)\n",
    "        m_r, m_i, m_n = gate_m.chunk(3, 1)\n",
    "\n",
    "        resetgate = torch.sigmoid(i_r + h_r + m_r)\n",
    "        inputgate = torch.sigmoid(i_i + h_i + m_i)\n",
    "        newgate = torch.tanh(i_n + (resetgate * h_n) + m_n)\n",
    "\n",
    "        hy = newgate + inputgate * (hidden - newgate)\n",
    "\n",
    "        return hy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUDModel(nn.Module):\n",
    "    def __init__(self, input_dim_cnn, input_dim, hidden_dim, layer_dim, output_dim, bias=True):\n",
    "        super(GRUDModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        self.gru_cell = GRUDCell(input_dim_cnn, input_dim, hidden_dim, layer_dim)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self,x_cnn, x, mask, delta):\n",
    "\n",
    "        # Initialize hidden state with zeros\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        # print(x.shape,\"x.shape\")100, 28, 28\n",
    "        if torch.cuda.is_available():\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "\n",
    "        outs = []\n",
    "\n",
    "        hn = h0[0, :, :]\n",
    "\n",
    "        for seq in range(x.size(1)):\n",
    "            hn = self.gru_cell(x_cnn[:, seq, :], x[:, seq, :], mask[:, seq, :], delta[:, seq, :], hn)\n",
    "            outs.append(hn)\n",
    "\n",
    "        out = outs[-1].squeeze()\n",
    "\n",
    "        out = self.fc(out)\n",
    "        # out = F.softmax(out, dim=1)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
